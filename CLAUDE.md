# CLAUDE.md â€” GestureDispatch (SignalFire)

## Project Overview

GestureDispatch is a hackathon project: AI-powered code snippets triggered by hand gestures. A developer selects code, makes a hand sign at their webcam, and the gesture dispatches a Claude API call with that code as context. The result streams into an output panel and auto-copies to clipboard.

**Core loop:** Select code â†’ Gesture â†’ Claude API â†’ Stream result â†’ Clipboard

## Team

- **Bishesh** â€” Detection & UI Shell (camera, MediaPipe, gesture classifier, visual feedback)
- **Sam** â€” AI Pipeline & Output (dispatcher, Claude API streaming, output panel, clipboard)

## Tech Stack

| Layer | Choice |
|-------|--------|
| Bundler | Vite (vanilla JS template) |
| Language | Vanilla JS â€” no TypeScript |
| Hand Detection | MediaPipe Hands via CDN |
| AI | Claude API (claude-sonnet-4-6) via raw `fetch()` with SSE streaming |
| UI | Single HTML page + CSS â€” no framework |
| Context | Clipboard API (`navigator.clipboard`) |

## Project Structure

```
gesture-dispatch/
â”œâ”€â”€ index.html              â† layout, camera feed, output panel, history
â”œâ”€â”€ style.css               â† all styling
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.js             â† entry: camera init, MediaPipe setup, gesture loop, keyboard fallback
â”‚   â”œâ”€â”€ gestures.js         â† landmark â†’ gesture classifier (5 gestures)
â”‚   â”œâ”€â”€ dispatcher.js       â† dispatch(gesture, code) â†’ Claude API â†’ stream â†’ clipboard
â”‚   â”œâ”€â”€ sounds.js           â† Web Audio API tone generator for gesture feedback
â”‚   â””â”€â”€ history.js          â† session history storage and rendering
â”œâ”€â”€ vite.config.js          â† dev server config (API proxy if needed)
â”œâ”€â”€ .env                    â† ANTHROPIC_API_KEY (gitignored)
â””â”€â”€ .env.example            â† template for env vars
```

## Key Conventions

- **No frameworks.** Vanilla DOM manipulation only. `document.getElementById`, `classList`, `textContent`.
- **No TypeScript.** Speed over safety for the hackathon.
- **No npm dependencies beyond Vite.** MediaPipe loads from CDN. Claude API via raw `fetch()`.
- **Single-page app.** Everything renders in `index.html`. No routing.
- **Module pattern.** Each JS file exports functions. `main.js` wires them together.

## Interface Contract

Bishesh's gesture detection calls Sam's dispatcher:

```js
import { dispatch } from './dispatcher.js';

// On gesture detected:
dispatch(gestureName, clipboardCode);

// On open palm (abort):
dispatch('open_palm');
```

## Gesture Vocabulary

| Gesture | Sign | Action | Keyboard Fallback |
|---------|------|--------|-------------------|
| âœŒï¸ Peace | Index + middle up | Fix bug | `1` |
| ğŸ‘ Thumbs up | Thumb extended | Explain code | `2` |
| ğŸ¤™ Hang loose | Thumb + pinky out | Commit message | `3` |
| ğŸ¤˜ Rock on | Index + pinky up | Scaffold test | `4` |
| âœ‹ Open palm | All fingers up | Abort stream | `5` |

## Gesture Classifier Rules

```
Finger extended = tip y-position < pip y-position (tip higher than knuckle)

peace()      â†’ index AND middle AND NOT ring AND NOT pinky
thumbs_up()  â†’ thumb AND NOT index AND NOT middle AND NOT ring AND NOT pinky
hang_loose() â†’ thumb AND pinky AND NOT index AND NOT middle AND NOT ring
rock_on()    â†’ index AND pinky AND NOT middle AND NOT ring
open_palm()  â†’ all five extended
```

- Confidence threshold: 0.85
- Debounce: 1 second between dispatches
- Confidence ring: 0.8s hold required before dispatch fires

## Core PRD + Expansions

- **Core PRD:** `gesture-dispatch-prd.md`
- **Expansions:** `prd-expansion.md`
- **Bishesh's scope:** `bishesh-detection-ui.md`
- **Sam's scope:** `sam-ai-pipeline.md`

### Expansion Features (beyond MVP)

1. **Confidence ring** â€” radial SVG animation, 0.8s hold before dispatch (Bishesh)
2. **Session history** â€” scrollable log of past dispatches with re-copy (Sam + Bishesh)
3. **Keyboard fallback** â€” keys 1-5 map to gestures (Bishesh)
4. **Onboarding overlay** â€” "hold up a hand to begin" first-load state (Bishesh)
5. **Sound cues** â€” Web Audio API tones per gesture event (Bishesh)
6. **Error handling UX** â€” inline error messages for camera/clipboard/API failures (Sam + Bishesh)

## Build & Run

```bash
npm install
npm run dev        # starts Vite dev server
```

Requires `ANTHROPIC_API_KEY` in `.env`.

## Demo Prep

- Demo buggy function: `def calculate_average(nums): return sum(nums) / len(nums)`
- Demo arc: onboarding â†’ âœŒï¸ fix â†’ ğŸ‘ explain â†’ ğŸ¤™ commit â†’ keyboard fallback â†’ abort
- Fallback: hardcoded demo code string if clipboard permission fails
- Fallback: cached response if network fails
- Sound mute: press `M` if demo room audio is problematic

## Judging Criteria

| Criterion | How We Address It |
|-----------|------------------|
| **Problem Statement** | Snippet analogy â€” judges have felt this pain. AI dispatch cost is too high. |
| **Creativity** | Confidence ring, sound design, gesture-as-snippet concept. Multi-sensory UX. |
| **Completeness** | Full loop + history + error handling + keyboard fallback + onboarding. |
